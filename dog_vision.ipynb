{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!unzip \"drive/MyDrive/dog-breed-identification.zip\" -d \"drive/MyDrive/Dog Vision/\""
      ],
      "metadata": {
        "id": "bDnIixKCT7iY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End-to-End Multi Class DOG BREED CLASSIFICATION\n",
        "\n",
        "This notebook builds an End-to-end Multi-class Image classifier using TensorFlow 2.0 and TensorFlow Hub.\n",
        "\n",
        "##1.Problem\n",
        "\n",
        "Identifying the breed of a dog given an image of a dog.\n",
        "\n",
        "##2. Data\n",
        "\n",
        "The Data we're using is from Kaggle's Dog Breed Identification Competition.\n",
        "\n",
        "https://www.kaggle.com/c/dog-breed-identification/data\n",
        "\n",
        "\n",
        "##3. Evaluation\n",
        "\n",
        "The Evaluation is a File with Prediction Probabilities for each dog breed of each test image.\n",
        "\n",
        "##4. Features\n",
        "\n",
        "Some information about the data:\n",
        "* We're dealing with images (Unstructured Data) so its best we use DEEP LEARNING\n",
        "* There are 120 breeds of Dogs (There are 120 Different Classes).\n",
        "* There are around 10,000+ images in both Training and Test Sets."
      ],
      "metadata": {
        "id": "WIdGGAOHZpIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get our Workspace Ready\n",
        "\n",
        "* Import TensorFlow 2.x\n",
        "* Import TensorFlow Hub\n",
        "* Make sure we're using a GPU"
      ],
      "metadata": {
        "id": "ThM9BQVQdAxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow into Colab\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(\"TF Version:\", tf.__version__)\n",
        "print(\"TF Hub Version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU Availability\n",
        "print(\"GPU\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "-H1ys-rFX89z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9190bb64-3178-4c92-f26c-d256204a3fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version: 2.17.0\n",
            "TF Hub Version: 0.16.1\n",
            "GPU not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting our Data Ready (Turning into Tensors)\n",
        "\n",
        "We Turn our images to Tensors(numerical representations).\n",
        "\n",
        "Let's start by accessing our data and checking out the labels.\n"
      ],
      "metadata": {
        "id": "qDmbkCZVdSmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"/content/drive/MyDrive/Dog Vision/labels.csv\")\n",
        "labels_csv.head()"
      ],
      "metadata": {
        "id": "ZMDNXxToj7lh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d6cc4b87-af11-41c1-ccbd-f3ed8bc12b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Dog Vision/labels.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3c1c5a039b85>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Dog Vision/labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlabels_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dog Vision/labels.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TCAYyGZIo_KB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a724f03f-a96f-4153-cb2f-d9ab90fd3077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.describe()"
      ],
      "metadata": {
        "id": "VcnUkPXmkOY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images are there of each breed\n",
        "\n",
        "labels_csv[\"breed\"].value_counts()"
      ],
      "metadata": {
        "id": "nLAaDW7kkTC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv['breed'].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "HO3JD8UVkzm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv['breed'].value_counts().median()"
      ],
      "metadata": {
        "id": "-t16SUkxlDZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's View an Image\n",
        "from IPython.display import Image\n",
        "\n",
        "Image(\"drive/MyDrive/Dog Vision/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
      ],
      "metadata": {
        "id": "VSROtvbglQ8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Images and Their Labels\n",
        "\n",
        "Let's get a list of all of our image file pathnames."
      ],
      "metadata": {
        "id": "77ksAGRdmUQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.head()"
      ],
      "metadata": {
        "id": "ZkIX7I0emnfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = [\"drive/MyDrive/Dog Vision/train/\" + fname for fname in labels_csv[\"id\"].values + \".jpg\"]\n",
        "filenames[:10]"
      ],
      "metadata": {
        "id": "E-UOa_3DmqLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether number of filenames matches number of actual image files\n",
        "import os\n",
        "if len(os.listdir(\"/content/drive/MyDrive/Dog Vision/train\")) == len(filenames):\n",
        "  print(\"Filenames match actual amount of files!\")"
      ],
      "metadata": {
        "id": "kqofI5yZmyel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One More Check\n",
        "Image(filenames[9000])"
      ],
      "metadata": {
        "id": "PLmN5ix7nh32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv[\"breed\"][9000]"
      ],
      "metadata": {
        "id": "Oh9i4mZWoam1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wah29WxIohwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we now got our Training Image Filepaths in a list,\n",
        "Let's prepare our labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "9u6uDfl7o2hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = labels_csv['breed']\n",
        "labels"
      ],
      "metadata": {
        "id": "EAeYfWVco-Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "labels = np.array(labels)\n",
        "labels"
      ],
      "metadata": {
        "id": "BpoGU1IupAvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if No. of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames!\")"
      ],
      "metadata": {
        "id": "yooIquVYpGxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "5HVD4f8ppanv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Single Label into a Array of Booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "metadata": {
        "id": "6Nz0iM14qcNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn every label into a Boolean Array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "Bz4sGxGMqzjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Turning boolean array into integers\n",
        "\n",
        "print(labels[0])\n",
        "print(np.where(unique_breeds == labels[0])[0][0]) # Index where Label Occurs\n",
        "print(boolean_labels[0].argmax()) # Index where Label Occurs\n",
        "print(boolean_labels[0].astype(int))"
      ],
      "metadata": {
        "id": "UoRmOd4grmHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[2])\n",
        "print(boolean_labels[2].astype(int))"
      ],
      "metadata": {
        "id": "9L8NABWqr56p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames[:10]"
      ],
      "metadata": {
        "id": "jpBAFRVVsLZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating our Own Validation Set\n",
        "\n",
        "Since the dataset from Kaggle doesn't come with a Validation Set, we're going to create our own."
      ],
      "metadata": {
        "id": "zOhGm07uOiz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X & y Variables\n",
        "\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "yGdmcJadPMpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "id": "FXOA3rgfPcCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to start off Experimenting with ~1000 images and increase as needed."
      ],
      "metadata": {
        "id": "6vBNoSMVPn3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Number of Images to use for Experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\",min:1000,max:10000,step:1000}"
      ],
      "metadata": {
        "id": "A6tq0Wt5PxXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "# Split them into Training and Validation of Total size NUM_IMAGES\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES],\n",
        "                                                  test_size=0.2)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "MoMNBLK5QJVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "8wsy54FKQnLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Images (Turning Images into Tensors)\n",
        "\n",
        "To Preprocess our images to Tensors, we're going to write a Function which does a Few things\n",
        "1. Take an Image Filepath as Input\n",
        "2. Use Tensorflow to read the file and save it to a variable `image`\n",
        "3. Turn our `image` into TENSORS\n",
        "4. Resize the image to be shape of (224,224)\n",
        "5. Return the Modified Image\n",
        "\n",
        "Before we do, let's see what importing an Image looks like."
      ],
      "metadata": {
        "id": "9cZfFwc2RFN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42])\n",
        "image.shape"
      ],
      "metadata": {
        "id": "ksaM8L3LRU3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "IDI88xgHShB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.max() , image.min()"
      ],
      "metadata": {
        "id": "ufhpqk5CSwp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn image into a Tensor\n",
        "tf.constant(image)"
      ],
      "metadata": {
        "id": "YdC0HBFeS2NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Take an Image Filepath as Input\n",
        "\n",
        "2.Use Tensorflow to read the file and save it to a variable image\n",
        "\n",
        "3.Turn our image into TENSORS\n",
        "\n",
        "4. Normalise our Image (Convert Colour Channels values from 0-255 to 0-1)\n",
        "\n",
        "4.Resize the image to be shape of (224,224)\n",
        "\n",
        "5.Return the Modified Image"
      ],
      "metadata": {
        "id": "ijVg6iCzS_FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "# Create a Function for PreProcessing Images\n",
        "def process_image(image_path,img_size=IMG_SIZE):\n",
        "  \"\"\"\n",
        "  Takes an Image File Path and turns the image into a Tensor\n",
        "  \"\"\"\n",
        "  # Read in an Image File\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the JPEG Image to Numerical Tensor with 3 Colour Channels (R,G,B)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the Colour Channel values from 0-255 to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image,tf.float32)\n",
        "  # Resize the Image\n",
        "  image = tf.image.resize(image,size=[IMG_SIZE,IMG_SIZE])\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "yTLnl1lEmCeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TURNING DATA INTO BATCHES\n",
        "\n",
        "Why turn our Data into batches?\n",
        "\n",
        "Let's say you're trying to process 10000 images in one go...they all might not fit into memory.\n",
        "\n",
        "So that's why we do 32 images (BATCH SIZE) at a time.\n",
        "\n",
        "In order to use TensorFlow effectively, we need our data in the form of Tensor Tuples which look like this: `(image,label)`"
      ],
      "metadata": {
        "id": "VpMozra8oWBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Simple Function to return a Tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "\n",
        "  image = process_image(image_path)\n",
        "  return image, label\n"
      ],
      "metadata": {
        "id": "_iEXHlW3qcS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(process_image(X[42]), tf.constant(y[42]))"
      ],
      "metadata": {
        "id": "t_bu9Ba4rU5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a way to turn our data into tuples of Tensors in the form: `(image,label)` ,let's make a funciton to convert all of our data (X & y) into Batches."
      ],
      "metadata": {
        "id": "LdN5NxKBXlY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Batch Size, 32 is a Good Start\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a Function to convert Data into Batches\n",
        "def create_data_batches(X,y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image X and label y pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle if it's Validation Data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a Test Data, we probably don't have labels.\n",
        "\n",
        "  if test_data:\n",
        "    print(\"Creating Test Data Batches..\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) # Only Filepaths no Labels\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  elif valid_data:\n",
        "    print('Creating Validation Data Batches..')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
        "                                               tf.constant(y)))\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "  else:\n",
        "    print(\"Creating Training Data Batches...\")\n",
        "    # Turn FilePaths and Labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n",
        "                                               tf.constant(y)))\n",
        "\n",
        "    # Shuffling Pathnames and Labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(X))\n",
        "    # Create (image,label) tuples .\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the Training Data into Batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "\n",
        "  return data_batch"
      ],
      "metadata": {
        "id": "KN1gXLXNX0GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Training and Validation Batches\n",
        "\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "metadata": {
        "id": "jBtwQvjSb5Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.element_spec, val_data.element_spec"
      ],
      "metadata": {
        "id": "JIlu2efIcZAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising Data Batches\n",
        "\n",
        "Our Data is now in batches, however, these can be a little hard to understand.\n",
        "Let's Visualise them."
      ],
      "metadata": {
        "id": "PcOa9pjNck8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a Function for Viewing Images in a Data Batch...\n",
        "def show_25_images(images,labels):\n",
        "  \"\"\"\n",
        "  Displays a Plot of 25 images and their labels from a data batch.\n",
        "  \"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "    # Create Subplots (5 rows , 5 columns)\n",
        "    ax = plt.subplot(5,5,i+1)\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "GECh19fndL_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "v7rB1hOvesEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's Visualise the Data in a Training Batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "\n",
        "show_25_images(train_images, train_labels)"
      ],
      "metadata": {
        "id": "Ie27Q3vHfUdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualise our Validation Set\n",
        "\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images, val_labels)"
      ],
      "metadata": {
        "id": "FeA-CWNsfmsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Model\n",
        "\n",
        "Before we build a Model, there are a few things we need to define\n",
        "\n",
        "* The `input` shape (Our Images shape, in the form of Tensors) to our Model.\n",
        "\n",
        "* The output Shape( Image Labels, in the form of Tensors) of our Model.\n",
        "\n",
        "* The URL of the model we want to use."
      ],
      "metadata": {
        "id": "ZbgkmZZTgTq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input shape to the Model\n",
        "\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # Batch, Height , Width , Color Channels\n",
        "\n",
        "# Setup Output shape of our Model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# Setup Model URL from Tensorflow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\"\n"
      ],
      "metadata": {
        "id": "X9DPOLPRqnS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got our inputs , outputs and model ready to go.\n",
        "Let's put them together into a Keras Deep Learning Model!\n",
        "\n",
        "Knowing this, let's create a function which:\n",
        "* Takes the input shape, output shape and the model we've chosen as parameters.\n",
        "* Defines the Layers in a Keras Model in Sequential fashion.\n",
        "* Compiles the Model (says how it should be evaluated and improved).\n",
        "* Builds the model\n",
        "* Returns the Model."
      ],
      "metadata": {
        "id": "ih1aZbWiVTKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-keras==2.15.1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nRoeTBs_7BAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE,\n",
        "                          activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
        "      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n",
        "      metrics=[\"accuracy\"] # We'd like this to go up\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "L2LvRp0YVyAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "peotCuqsW9ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = np.ones(shape=(1,1,1280))\n",
        "outputs"
      ],
      "metadata": {
        "id": "dolUxwVddKmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Callbacks\n",
        "\n",
        "Callbacks are helper functions a Model can use during training to do such things as save its progress, check its progress.\n",
        "\n",
        "We'll create two callbacks.\n",
        "\n",
        "1. One for Tensorboard which helps TRACK our Models Progress and\n",
        "\n",
        "2. One for Early Stopping which prevents our model from training for too long."
      ],
      "metadata": {
        "id": "nnqcPMKP75VJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TENSORBOARD Callback\n",
        "\n",
        "To setup a TensorBoard callback, we need to do 3 things:\n",
        "\n",
        "1. Load the TensorBoard Extension\n",
        "\n",
        "2. Create a TensorBoard Callback which is able to save logs to a Directory and pass it to our model's fit() function\n",
        "\n",
        "3. Visualise our Models with the %TensorBoard magic function."
      ],
      "metadata": {
        "id": "hysJWs5lBIhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TensorBoard Notebook Extension\n",
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "KlmcafMECDtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "# Create a function to build a TensorBoard Callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log direcotry for storing Tensorboard Logs\n",
        "  logdir = os.path.join(\"drive/MyDrive/Dog Vision/logs\",\n",
        "                        # Make it so the Logs gets tracked\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "metadata": {
        "id": "8Tkz7HOLCkFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Early Stopping Callback\n",
        "\n",
        "Early Stopping helps stop our model by Overfitting by stopping training if a certain metric stops improving."
      ],
      "metadata": {
        "id": "kyTKtFxbmGmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create early stopping callback\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3)"
      ],
      "metadata": {
        "id": "25iVlSoymvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Model\n",
        "\n",
        "Our first model is only going to train 1000 images, to make sure everything is working."
      ],
      "metadata": {
        "id": "zGJJVhSinELC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100 #@param {type: \"slider\", min:10,max:100,step: 10}\n",
        "\n"
      ],
      "metadata": {
        "id": "j8qOjuYKz1VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU\",\"available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\")"
      ],
      "metadata": {
        "id": "5bSq1eY41aUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a function which trains a Model.\n",
        "\n",
        "* Creating a Model using `create_model()`\n",
        "\n",
        "* Setup a TensorBoard callback using `create_tensorboard_callback()`\n",
        "\n",
        "* Call the `fit()` on our model passing it the Training Data, Validation Data, Number of epochs to train (NUM_EPOCHS) and the callbacks we'd like to use.\n",
        "\n",
        "* Return the Model\n",
        "\n"
      ],
      "metadata": {
        "id": "GPh1ENxN1Qyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a Function to train and return a Trained Model\n",
        "\n",
        "def train_model():\n",
        "\n",
        "  model = create_model()\n",
        "\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the Callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq = 1,\n",
        "            callbacks = [tensorboard, early_stopping]\n",
        "            )\n",
        "  return model"
      ],
      "metadata": {
        "id": "OXb5_J8H4rX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model()"
      ],
      "metadata": {
        "id": "X4pjn0N-8n3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question** It looks like our Model is OVERFITTING because it's performing far better on Training Set than Val Set\n",
        "What are some ways to model Overfitting in Deep Learning Neural Networks?\n",
        "\n",
        "**Note:** Overfitting to begin with is a good thing!"
      ],
      "metadata": {
        "id": "kZNMJAWM9ABR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking the TensorBoard Logs\n",
        "\n",
        "The Tensorboard Magic Function (%tensorboard) will access the logs directly and visualise its contents."
      ],
      "metadata": {
        "id": "W-ycmRvi-79u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir drive/MyDrive/Dog\\ Vision/logs"
      ],
      "metadata": {
        "id": "Agqysgnm_ZNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making and Evaluating Predictions using a Trained Model"
      ],
      "metadata": {
        "id": "QJxxUcWb_rqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "Bc3tN9jLtkzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions on the Validation Data\n",
        "predictions = model.predict(val_data, verbose=1)\n",
        "predictions"
      ],
      "metadata": {
        "id": "-lS616NdtOQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index= 42\n",
        "print(predictions[index])\n",
        "print(f\"Max Value (Probability of Prediction): {np.max(predictions[index])}\")\n",
        "print(f\"Sum: {np.sum(predictions[index])}\")\n",
        "print(f\"Max Index: {np.argmax(predictions[index])}\")\n",
        "print(f\"Predicted Label: {unique_breeds[np.argmax(predictions[index])]}\")"
      ],
      "metadata": {
        "id": "SbAqstLUuHor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having the above functionality is great, but we want to do it at scale.\n",
        "\n",
        "And it would be better to see the image the prediction is being made on..\n",
        "\n",
        "**Note:** Prediction Probabilities are also known as Confidence Levels."
      ],
      "metadata": {
        "id": "ZkOTgo3fIo2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn Prediction Probabilities into their Respective Label (easier to understand)\n",
        "\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an Array of Prediction Probabilities into a Label\n",
        "  \"\"\"\n",
        "\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a Predicted Label based on an array of Prediciton Probabilities\n",
        "\n",
        "pred_label = get_pred_label(predictions[81])\n",
        "\n",
        "pred_label"
      ],
      "metadata": {
        "id": "FifPhMCkOrlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data"
      ],
      "metadata": {
        "id": "XHd5MJILPV-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now since our val_data is still in a BATCH DATASET, we'll have to UNBATCHIFY it to make Predictions on the Validation Images and then Compare those Predictions to the Validation Labels."
      ],
      "metadata": {
        "id": "GRcOa3JMPjUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_ = []\n",
        "labels_ = []\n",
        "\n",
        "# Loop through Unbatched Data\n",
        "\n",
        "for image, label in val_data.unbatch().as_numpy_iterator():\n",
        "  images_.append(image)\n",
        "  labels_.append(label)\n",
        "\n",
        "images_[0] , labels_[0]"
      ],
      "metadata": {
        "id": "LGTbrObKP2YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(labels_[0])"
      ],
      "metadata": {
        "id": "NXQ-ZrL3QYG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred_label(predictions[0])"
      ],
      "metadata": {
        "id": "3T1kJVDIQ39y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a Batched Dataset of (image,label) tensors and returns seperate arrays of images and labels.\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  labels=[]\n",
        "\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "val_images, val_labels = unbatchify(val_data)\n",
        "val_images[0] , val_labels[0]"
      ],
      "metadata": {
        "id": "Oz04oI6MQ89S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got ways to get :\n",
        "\n",
        "* Prediction Labels\n",
        "* Validation Labels\n",
        "* Validation Images\n",
        "\n",
        "We'll create a Function which\n",
        "* Takes an Array of Prediciton Probs, an Array of Truth Labels, and images and Integers.\n",
        "* Convert the  Preds Probs to a predicted Label.\n",
        "\n",
        "* Plot the Predicted Label, its predicted Probability, the Truth label and the Target Image on a Single Label."
      ],
      "metadata": {
        "id": "UcNmP_6NROxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
        "  \"\"\"\n",
        "  View the Prediction, Ground Truth, and Image for a sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
        "\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Plot Image and Remove Ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the Colour of the Title\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  # Change the Plot Title to be Predicted\n",
        "  plt.title(\"{} {:2.0f}% {}\".format(pred_label, np.max(pred_prob) * 100,true_label), color= color)\n"
      ],
      "metadata": {
        "id": "giuUoZ5HS7ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(predictions,val_labels, val_images,n=2)"
      ],
      "metadata": {
        "id": "iLJhncPfUfKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got one function to Visualise our Model's Predictions, let's make another to view top 10 PREDICTIONS.\n",
        "\n",
        "This function will :\n",
        "* Take an Input of Prediction Probabilities array and a Ground Truth Array and an Integer\n",
        "* Find the Prediction using `get_pred_label()`\n",
        "* Find the top 10:\n",
        "  * Prediction Probabilites Indexes\n",
        "  * Prediction Probabilities Values\n",
        "  * Prediction Labels"
      ],
      "metadata": {
        "id": "nBDUQFBDVD9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
        "  \"\"\"\n",
        "  Plots the top 10 Highest Prediction Confidences along with the Truth  Label for Sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
        "\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Find the Top 10 Prediction\n",
        "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
        "\n",
        "  # Find the top 10 Prediction Confidence Levels\n",
        "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
        "\n",
        "  # Find the top 10 Prediciton Labels\n",
        "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
        "\n",
        "  # Setup Plot\n",
        "  top_plot = plt.bar(np.arange(len(top_10_pred_labels),),\n",
        "                     top_10_pred_values,\n",
        "                     color=\"grey\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),labels=top_10_pred_labels,rotation=\"vertical\")\n",
        "\n",
        "  if np.isin(true_label, top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "QCMUClofXpFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred_conf(predictions,val_labels, n=9)"
      ],
      "metadata": {
        "id": "_RJSCmO5YDuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some functions to help us Visualise our Predictions and Evaluate our Model"
      ],
      "metadata": {
        "id": "7f1lxbpmaVSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check out a Few Predictions and their Different Values\n",
        "i_multiplier = 10\n",
        "num_rows= 3\n",
        "num_cols =2\n",
        "\n",
        "num_images = num_rows * num_cols\n",
        "\n",
        "plt.figure(figsize=(10*num_cols, 5 * num_cols))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2* num_cols, 2*i + 1)\n",
        "  plot_pred(predictions,val_labels, val_images, n=i+i_multiplier)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_pred_conf(predictions, val_labels, i+i_multiplier)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iGFuM2HxeJV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving our Model"
      ],
      "metadata": {
        "id": "3ZfD6gFae6FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Function to save a model\n",
        "def save_model(model,suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a Given Model in a Model's Directory and appends a Suffix\n",
        "  \"\"\"\n",
        "  # Create a Model Directory pathname with current Time\n",
        "  modeldir = os.path.join(\"drive/MyDrive/Dog Vision/models\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" #Save Format of Model\n",
        "  print(f\"Saving Model to {model_path}...\")\n",
        "  model.save(model_path)\n",
        "\n",
        "  return model_path"
      ],
      "metadata": {
        "id": "WSvH6k8QgtZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Function to Load a Model\n",
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a Saved Model from a Specified Model\n",
        "  \"\"\"\n",
        "  print(f\"Loading Saved Model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path,\n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "metadata": {
        "id": "qKpDxfVYh0VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our Model Trained on 1000 Images\n",
        "save_model(model, suffix=\"1000-images-mobilenetv2-Adam\")"
      ],
      "metadata": {
        "id": "uGUNYIwVibtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a Trained Model\n",
        "loaded_1000_image_model = load_model(\"/content/drive/MyDrive/Dog Vision/models/20241105-13361730813789-1000-images-mobilenetv2-Adam.h5\")"
      ],
      "metadata": {
        "id": "5AxL85UiioPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Pre-saved Model\n",
        "model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "ojMnMBDOi94X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Loaded Model\n",
        "loaded_1000_image_model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "zjbkBBlwjUCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Big Dog Model (On the Full Data)"
      ],
      "metadata": {
        "id": "i3vs5hlojczn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Data Batch with the Full Dataset\n",
        "full_data = create_data_batches(X,y)\n"
      ],
      "metadata": {
        "id": "yCJZ26LE6QP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model = create_model()"
      ],
      "metadata": {
        "id": "L99aANrC6g46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model_tensorboard = create_tensorboard_callback()\n",
        "\n",
        "full_model_early_stopping = tf.keras.callbacks.EarlyStopping('accuracy',patience=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "vVa9iDw07GyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.fit(x=full_data, epochs=NUM_EPOCHS, callbacks=[full_model_tensorboard, full_model_early_stopping])"
      ],
      "metadata": {
        "id": "FGStzubd79Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_full_model = load_model('/content/drive/MyDrive/Dog Vision/models/20241106-05251730870742-1000-images-mobilenetv2-Adam.h5')"
      ],
      "metadata": {
        "id": "aBsrUApU8EvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions on the Test Dataset\n",
        "\n",
        "Since our model has been trained on images in the form of Tensor batches, to make predictions on the Test Data, we'll have to get it into the same dataset.\n",
        "\n",
        "Luckily we created `create_data_batches()` earlier which can take a list of filenames as input and convert them into Tensor Batches.\n",
        "\n",
        "To make Predictions on the Test Data, we'll:\n",
        "* Get the Test image filenames\n",
        "* Convert the filenmaes into test data batches using `create_data_batches` and setting the `test_data` parameter to `True` (since the test data doesn't have labels)\n",
        "\n",
        "* Make a Predicitons array by passign the test batches"
      ],
      "metadata": {
        "id": "xT8k_lEp-qDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test image filenames\n",
        "test_path = \"/content/drive/MyDrive/Dog Vision/test\"\n",
        "test_filenames = [test_path + \"/\" + fname for fname in os.listdir(test_path)]\n",
        "test_filenames[:10]"
      ],
      "metadata": {
        "id": "ir9tbqby-1zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_filenames)"
      ],
      "metadata": {
        "id": "8rYkGseLAXGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = create_data_batches(test_filenames, test_data=True)"
      ],
      "metadata": {
        "id": "fiPCNl2QA5Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "id": "O4TjV_moA9z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions on the Test Data Batch using the fully loaded Model\n",
        "test_predictions = loaded_full_model.predict(test_data, verbose=1)"
      ],
      "metadata": {
        "id": "ArqZgvFlBQuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Predictions (NumPy Array) to csv file\n",
        "np.savetxt(\"/content/drive/MyDrive/Dog Vision/preds_array.csv\", test_predictions, delimiter=\",\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zzwKvlKVDWfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = np.loadtxt(\"/content/drive/MyDrive/Dog Vision/preds_array.csv\", delimiter=\",\")"
      ],
      "metadata": {
        "id": "MyOtiWWNEAQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Dataset Predictions for Kaggle\n",
        "www.kaggle.com/competitions/dog-breed-identification/overview/evaluation\n"
      ],
      "metadata": {
        "id": "WY0YqJ1xEIF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Pandas DataFrame with Empty columns\n",
        "pred_df = pd.DataFrame(columns=[\"id\"] + list(unique_breeds))\n",
        "pred_df"
      ],
      "metadata": {
        "id": "4TpzfsrZIgaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append Test Image ID's to Predictions DataFrame\n",
        "test_ids = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
        "pred_df[\"id\"] = test_ids"
      ],
      "metadata": {
        "id": "9dtvfivvJJ1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the Prediction Probabilities to Each dog breed Column\n",
        "\n",
        "pred_df[list(unique_breeds)] = test_predictions\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "JxkKIYlmJoL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.to_csv(\"drive/MyDrive/Dog Vision/full_model_predictions_submission_1_mobilenetv2.csv\",index=False)\n"
      ],
      "metadata": {
        "id": "3_zK9A4CKOSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions on Custom Images\n",
        "\n",
        "To make Predictions on Custom Images"
      ],
      "metadata": {
        "id": "qNoiiW3HKfpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Custom Image File Path\n",
        "import os\n",
        "custom_path = \"drive/MyDrive/Dog Vision/custom_images\"\n",
        "custom_image_paths = [custom_path + \"/\" + fname for fname in os.listdir(custom_path)]\n",
        "custom_image_paths\n"
      ],
      "metadata": {
        "id": "TbW43l2yMUF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn Customn Images into Batch Dataset\n",
        "custom_data = create_data_batches(custom_image_paths)\n",
        "custom_data"
      ],
      "metadata": {
        "id": "bLjxAa-IP1-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_preds = loaded_full_model.predict(custom_data)\n",
        "custom_preds"
      ],
      "metadata": {
        "id": "IZwitKLQRGaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_DQmuURCLz7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_pred_labels = [get_pred_labels(custom_preds[i]) for i in range(len(custom_preds))]\n",
        "custom_pred_labels"
      ],
      "metadata": {
        "id": "2XvTEr1TRWsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Custom Images (Our Unbatchify() won't work since we don't have the Labels)\n",
        "\n",
        "custom_images = []\n",
        "\n",
        "for image in custom_data.unbatch().as_numpy_iterator():\n",
        "  custom_images.append(image)\n"
      ],
      "metadata": {
        "id": "b1b73OmeRizM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Custom Image Predictions\n",
        "plt.figure(figsize=(10,10))\n",
        "for i, image in enumerate(custom_images):\n",
        "  plt.subplot(1,3,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(custom_pred_labels[i])\n",
        "  plt.imshow(image)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R6BSSSLXR7RU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}